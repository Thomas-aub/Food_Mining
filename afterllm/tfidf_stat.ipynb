{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cf846a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "835e2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_RESULTS_FILE = 'ingredient_clusters_hdbscan.csv'\n",
    "RECIPES_FILE = '../data/clean_data/recipes_cleaned.csv'\n",
    "OUTPUT_CSV = 'cluster_characterization_automated_hdbscan.csv'\n",
    "OUTPUT_LATEX = 'cluster_table_hdbscan.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "822488ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cluster file columns: ['ingredient', 'cluster']\n",
      "  First few rows:\n",
      "             ingredient  cluster\n",
      "0                   NaN       -1\n",
      "1      a original sauce       -1\n",
      "2         abalone steak       -1\n",
      "3              absinthe       -1\n",
      "4  absolut kurant vodka       39\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "clusters_raw = pd.read_csv(CLUSTER_RESULTS_FILE)\n",
    "print(f\"  Cluster file columns: {clusters_raw.columns.tolist()}\")\n",
    "print(f\"  First few rows:\\n{clusters_raw.head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b8e0237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 42 clusters\n"
     ]
    }
   ],
   "source": [
    "# Group ingredients by cluster\n",
    "if 'cluster' in clusters_raw.columns and 'ingredient' in clusters_raw.columns:\n",
    "    clusters_df = clusters_raw.groupby('cluster')['ingredient'].apply(list).reset_index()\n",
    "    clusters_df.columns = ['cluster_id', 'ingredient_list']\n",
    "else:\n",
    "    raise ValueError(\"Expected columns 'cluster' and 'ingredient' in cluster results file\")\n",
    "\n",
    "print(f\" Loaded {len(clusters_df)} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0ca5977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading recipe data...\n",
      "Loaded 222705 recipes\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "# Load original recipes\n",
    "print(\"\\n Loading recipe data...\")\n",
    "df_recipes = pd.read_csv(RECIPES_FILE)\n",
    "# Parse ingredients column (adjust column name if different)\n",
    "ingredient_col = 'ingredients'  # or 'ingredients_y' based on your file\n",
    "if ingredient_col not in df_recipes.columns:\n",
    "    # Try alternative column names\n",
    "    for col in ['ingredients_y', 'ingredients_x', 'ingredient']:\n",
    "        if col in df_recipes.columns:\n",
    "            ingredient_col = col\n",
    "            break\n",
    "\n",
    "if isinstance(df_recipes[ingredient_col].iloc[0], str):\n",
    "    df_recipes[ingredient_col] = df_recipes[ingredient_col].apply(ast.literal_eval)\n",
    "\n",
    "print(f\"Loaded {len(df_recipes)} recipes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84edd0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Computing ingredient frequencies...\n",
      "  Processed 2080428 total ingredient occurrences\n",
      "  Found 14621 unique ingredients\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"\\n Computing ingredient frequencies...\")\n",
    "all_ingredients = []\n",
    "for ing_list in df_recipes[ingredient_col]:\n",
    "    all_ingredients.extend(ing_list)\n",
    "\n",
    "ingredient_freq = Counter(all_ingredients)\n",
    "print(f\"  Processed {len(all_ingredients)} total ingredient occurrences\")\n",
    "print(f\"  Found {len(ingredient_freq)} unique ingredients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2651f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing TF-IDF for distinctive terms...\n",
      " TF-IDF computed (24267 terms)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "print(\"\\nComputing TF-IDF for distinctive terms...\")\n",
    "\n",
    "# Treat each cluster as a document, filter out non-string items\n",
    "cluster_docs = [' '.join([ing for ing in ing_list if isinstance(ing, str)]) for ing_list in clusters_df['ingredient_list']]\n",
    "\n",
    "# Compute TF-IDF\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=None,\n",
    "    min_df=1,\n",
    "    ngram_range=(1, 2),  # Allow bigrams\n",
    "    token_pattern=r'[a-zA-Z]+'\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(cluster_docs)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\" TF-IDF computed ({len(feature_names)} terms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c45c6c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Characterizing clusters...\n",
      "  Characterized 42 clusters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"\\n Characterizing clusters...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in clusters_df.iterrows():\n",
    "    cluster_id = row['cluster_id']\n",
    "    ingredients = row['ingredient_list']\n",
    "    \n",
    "    # basic stats\n",
    "    size = len(ingredients)\n",
    "\n",
    "    # frequency analysis\n",
    "    freqs = [ingredient_freq.get(ing, 0) for ing in ingredients]\n",
    "    \n",
    "    if len(freqs) == 0:\n",
    "        continue  # Skip empty clusters\n",
    "        \n",
    "    avg_freq = np.mean(freqs)\n",
    "    min_freq = np.min(freqs)\n",
    "    max_freq = np.max(freqs)\n",
    "    # Top 5 ingredients by frequency\n",
    "    ing_with_freq = [(ing, ingredient_freq.get(ing, 0)) for ing in ingredients]\n",
    "    ing_with_freq.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_5_by_freq = ', '.join([ing for ing, _ in ing_with_freq[:5]])\n",
    "    \n",
    "    # === TF-IDF DISTINCTIVE TERMS ===\n",
    "    tfidf_scores = tfidf_matrix[i].toarray().flatten()\n",
    "    top_tfidf_indices = tfidf_scores.argsort()[-5:][::-1]\n",
    "    distinctive_terms = [\n",
    "        feature_names[idx] \n",
    "        for idx in top_tfidf_indices \n",
    "        if tfidf_scores[idx] > 0\n",
    "    ]\n",
    "    distinctive_str = ', '.join(distinctive_terms[:5])\n",
    "    \n",
    "    results.append({\n",
    "        'Cluster': cluster_id,\n",
    "        'Size': size,\n",
    "        'Distinctive_Terms': distinctive_str,\n",
    "        'Top_5_Frequent': top_5_by_freq,\n",
    "        'Avg_Freq': int(avg_freq),\n",
    "        'Min_Freq': min_freq,\n",
    "        'Max_Freq': max_freq\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "# Sort by cluster size (descending)\n",
    "results_df = results_df.sort_values('Size', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"  Characterized {len(results_df)} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de51d162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 clusters by size:\n",
      "\n",
      " Cluster  Size                                Distinctive_Terms                                                                                     Top_5_Frequent Avg_Freq  Min_Freq  Max_Freq\n",
      "      -1  8797               cheese, chicken, sauce, mix, dried                                                              salt, butter, sugar, onion, olive oil      137         0     86964\n",
      "      39   184            liqueur, juice, yogurt, vodka, orange                                                 orange juice, lime juice, banana, orange zest, ice      109         0      4490\n",
      "      15    90             pasta, pizza, sauce, italian, tomato                    parmesan cheese, mozzarella cheese, ricotta cheese, crushed tomatoes, spaghetti      454         0     15182\n",
      "      34    62               tortilla, corn, beans, chile, taco                                salsa, monterey jack cheese, jalapeno pepper, jalapeno, frozen corn      279         0      2764\n",
      "      30    53           paste, sauce, noodles, chinese, sesame                              sesame oil, rice vinegar, fish sauce, hoisin sauce, rice wine vinegar      282         0      3050\n",
      "      12    38                tuna, pickle, relish, dill, salad                                                  mayonnaise, mustard, crabmeat, tuna, lettuce leaf      344         0      8367\n",
      "      40    38      cream, chocolate, liqueur, vodka, ice cream                            whipped cream, kahlua, baileys irish cream, coffee liqueur, irish cream       76         0      1225\n",
      "      13    33             ribs, pork, mustard, pork ribs, corn                              worcestershire sauce, ketchup, prepared mustard, liquid smoke, catsup      494         0      7528\n",
      "      29    32              dal, powder, seeds, gram, coriander                         cumin seed, garam masala, mustard seeds, red chili powder, turmeric powder      173         1       834\n",
      "      31    29               syrup, ice cream, ice, cream, soda                                    milk, banana syrup, basil seeds, bubblegum, caramel pudding mix      892         0     25839\n",
      "      22    27           yeast, bread, dry, bread flour, gluten                                           warm water, bread flour, yeast, dry yeast, powdered milk      266         0      2057\n",
      "       5    24      cake, white cake, reducedfat, white, powder                                     egg white, cream of tartar, diet soda, cherry extract, violets      115         0      1655\n",
      "      25    24   flour, wheat, bran, bran oat, sugar substitute                            whole wheat flour, rolled oats, splenda sugar substitute, oatmeal, oats      512         0      3075\n",
      "      32    23                     wine, soda, cherry, ice, tea                     cherry powdered drink mix, gummy fish, ice wine, shochu, any desired flavoring        0         0         2\n",
      "      28    23        cake mix, cake, mix, brownie mix, brownie                         yellow cake mix, chocolate cake mix, brownie mix, cake mix, lemon cake mix       90         0       897\n",
      "      17    22     dried, honey, tea, white chai, currant juice                        honey, dried peppermint, yogurt starter, brewed hibiscus tea, geranium leaf      438         1      9620\n",
      "      26    21 chips, chocolate chips, butter, chocolate, candy          chocolate chips, butterscotch chips, rice krispies, salted peanuts, crunchy peanut butter      205         0      2238\n",
      "      38    20  chocolate, crumbs, powder, cookie, cocoa powder cocoa powder, unsweetened cocoa powder, semisweet chocolate, graham cracker crumbs, dark chocolate      376         1      1595\n",
      "      27    20              mix, cake mix, coconut, cake, green                      oil, new kitty litter box, clear creme de menthe, licorice whips, onion skins      498         0      9951\n",
      "      20    19       ground, pumpkin, instant tea, instant, tea                    ground cinnamon, ground nutmeg, ground cloves, ground allspice, ground cardamom      806         0      6954\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 20 clusters by size:\\n\")\n",
    "\n",
    "# Display with better formatting\n",
    "display_df = results_df.head(20).copy()\n",
    "display_df['Avg_Freq'] = display_df['Avg_Freq'].apply(lambda x: f\"{x:,}\")\n",
    "print(display_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "# Save to LaTeX (for report)\n",
    "# Create a cleaner version for LaTeX\n",
    "latex_df = results_df.head(20).copy()\n",
    "latex_df.columns = ['ID', 'Size', 'Distinctive Terms', 'Most Frequent', 'Avg Freq', 'Min', 'Max']\n",
    "latex_df.to_latex(OUTPUT_LATEX, index=False, escape=False, column_format='lllllll')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c41aea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total clusters analyzed: 42\n",
      "\n",
      "Cluster size distribution:\n",
      "  Min: 10\n",
      "  25th percentile: 13\n",
      "  Median: 17\n",
      "  75th percentile: 26\n",
      "  Mean: 234.9\n",
      "  Max: 8797\n",
      "\n",
      "Average frequency distribution:\n",
      "  Min: 0\n",
      "  Median: 280\n",
      "  Mean: 451.0\n",
      "  Max: 2,713\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal clusters analyzed: {len(results_df)}\")\n",
    "\n",
    "print(f\"\\nCluster size distribution:\")\n",
    "print(f\"  Min: {results_df['Size'].min()}\")\n",
    "print(f\"  25th percentile: {results_df['Size'].quantile(0.25):.0f}\")\n",
    "print(f\"  Median: {results_df['Size'].median():.0f}\")\n",
    "print(f\"  75th percentile: {results_df['Size'].quantile(0.75):.0f}\")\n",
    "print(f\"  Mean: {results_df['Size'].mean():.1f}\")\n",
    "print(f\"  Max: {results_df['Size'].max()}\")\n",
    "\n",
    "print(f\"\\nAverage frequency distribution:\")\n",
    "print(f\"  Min: {results_df['Avg_Freq'].min():,}\")\n",
    "print(f\"  Median: {results_df['Avg_Freq'].median():,.0f}\")\n",
    "print(f\"  Mean: {results_df['Avg_Freq'].mean():,.1f}\")\n",
    "print(f\"  Max: {results_df['Avg_Freq'].max():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3b16cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 5 LARGEST clusters:\n",
      " Cluster  Size                      Distinctive_Terms                                                                  Top_5_Frequent\n",
      "      -1  8797     cheese, chicken, sauce, mix, dried                                           salt, butter, sugar, onion, olive oil\n",
      "      39   184  liqueur, juice, yogurt, vodka, orange                              orange juice, lime juice, banana, orange zest, ice\n",
      "      15    90   pasta, pizza, sauce, italian, tomato parmesan cheese, mozzarella cheese, ricotta cheese, crushed tomatoes, spaghetti\n",
      "      34    62     tortilla, corn, beans, chile, taco             salsa, monterey jack cheese, jalapeno pepper, jalapeno, frozen corn\n",
      "      30    53 paste, sauce, noodles, chinese, sesame           sesame oil, rice vinegar, fish sauce, hoisin sauce, rice wine vinegar\n",
      "\n",
      " Top 5 clusters with MOST FREQUENT ingredients:\n",
      " Cluster  Size  Avg_Freq                                                                                                       Top_5_Frequent\n",
      "      33    13      2713                                 water, apple cinnamon cheerios, bergamot leaves, blueberry schnapps, cranberry vodka\n",
      "       1    10      2210                                 pepper, italian sweet vermouth, avgolemono sauce, chestnut meats, corned beef spread\n",
      "       7    12       986                tomatoes, roasted bell pepper hummus, astragalus root, fry bread, sour cream and bacon salad dressing\n",
      "       4    10       977 unsalted butter, bourbon biscuits, bushmills whiskey, candy lemon slices, chocolate hazelnut chocolate chip biscuits\n",
      "      31    29       892                                                      milk, banana syrup, basil seeds, bubblegum, caramel pudding mix\n",
      "\n",
      " Top 5 SMALLEST clusters (niche ingredients):\n",
      " Cluster  Size  Avg_Freq                                                                                                                  Top_5_Frequent\n",
      "       4    10       977            unsalted butter, bourbon biscuits, bushmills whiskey, candy lemon slices, chocolate hazelnut chocolate chip biscuits\n",
      "      11    10       578                                    walnuts, blackberry syrup, ginger wafer cookie, instant cinnamon roll oatmeal, maple liqueur\n",
      "       1    10      2210                                            pepper, italian sweet vermouth, avgolemono sauce, chestnut meats, corned beef spread\n",
      "       6    10        64                                                            pie crust, pie shell, pastry shells, deep dish pie shell, pie pastry\n",
      "      37    11         0 blueberry ice cream, chocolate liqueur cups, dole pineapple, organic peanut butter, passion fruit and strawberry salad dressing\n",
      "\n",
      " Top 5 clusters with RAREST ingredients:\n",
      " Cluster  Size  Avg_Freq                                                                                                                                          Top_5_Frequent\n",
      "      32    23         0                                                                          cherry powdered drink mix, gummy fish, ice wine, shochu, any desired flavoring\n",
      "       2    13         0                                  blended scotch whisky, chunky turkey pot pie soup, dried kelp granules, el torito adobo al pastor sauce, granary bread\n",
      "      37    11         0                         blueberry ice cream, chocolate liqueur cups, dole pineapple, organic peanut butter, passion fruit and strawberry salad dressing\n",
      "      24    16         1                                  peanut butter captain crunch cereal, caramel squares, lucky charms cereal, candy coated chocolate eggs, candy pumpkins\n",
      "       8    16         4 skinless chicken breast, barbecue potato chips, chicken coating mix, frozen mozzarella garlic bread, simply potatoes steakhouse seasoned diced potatoes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Largest clusters\n",
    "print(\"\\n Top 5 LARGEST clusters:\")\n",
    "largest = results_df.nlargest(5, 'Size')[['Cluster', 'Size', 'Distinctive_Terms', 'Top_5_Frequent']]\n",
    "print(largest.to_string(index=False))\n",
    "\n",
    "# Most frequent clusters (common ingredients)\n",
    "print(\"\\n Top 5 clusters with MOST FREQUENT ingredients:\")\n",
    "most_frequent = results_df.nlargest(5, 'Avg_Freq')[['Cluster', 'Size', 'Avg_Freq', 'Top_5_Frequent']]\n",
    "print(most_frequent.to_string(index=False))\n",
    "\n",
    "# Smallest clusters (niche/rare)\n",
    "print(\"\\n Top 5 SMALLEST clusters (niche ingredients):\")\n",
    "smallest = results_df.nsmallest(5, 'Size')[['Cluster', 'Size', 'Avg_Freq', 'Top_5_Frequent']]\n",
    "print(smallest.to_string(index=False))\n",
    "\n",
    "# Low-frequency clusters (rare ingredients)\n",
    "print(\"\\n Top 5 clusters with RAREST ingredients:\")\n",
    "rarest = results_df.nsmallest(5, 'Avg_Freq')[['Cluster', 'Size', 'Avg_Freq', 'Top_5_Frequent']]\n",
    "print(rarest.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b02fc150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Most COHESIVE clusters (low frequency variance):\n",
      " Cluster  Size  Avg_Freq  Freq_Std                                                     Distinctive_Terms\n",
      "       2    13         0  0.421325  turkey, torito adobo, turkey slices, lightlife turkey, chunky turkey\n",
      "      37    11         0  0.445362 cups, cream, shortcake, yogurtcovered pretzels, topping fruitflavored\n",
      "      32    23         0  0.624030                                          wine, soda, cherry, ice, tea\n",
      "      24    16         1  1.089725                     caramel, milk chocolate, candy, chocolate, cereal\n",
      "       8    16         4 10.638961                          chicken, parmesan, mozzarella, potatoes, and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/6f00l5q90dz_dlmyjws1fv1h0000gn/T/ipykernel_49408/1020590673.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1549.092918822456' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  results_df.loc[results_df['Cluster'] == row['cluster_id'], 'Freq_Std'] = freq_std\n"
     ]
    }
   ],
   "source": [
    "# Compute intra-cluster frequency variance (cohesion indicator)\n",
    "results_df['Freq_Std'] = 0\n",
    "for i, row in clusters_df.iterrows():\n",
    "    ingredients = row['ingredient_list']\n",
    "    freqs = [ingredient_freq.get(ing, 0) for ing in ingredients]\n",
    "    if len(freqs) > 1:\n",
    "        freq_std = np.std(freqs)\n",
    "        results_df.loc[results_df['Cluster'] == row['cluster_id'], 'Freq_Std'] = freq_std\n",
    "\n",
    "# Clusters with low frequency variance = more cohesive\n",
    "print(\"\\n Most COHESIVE clusters (low frequency variance):\")\n",
    "cohesive = results_df.nsmallest(5, 'Freq_Std')[['Cluster', 'Size', 'Avg_Freq', 'Freq_Std', 'Distinctive_Terms']]\n",
    "print(cohesive.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "713ff174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLUSTERS RANKED BY INTERPRETABILITY ===\n",
      "    Cluster                   Category_Label  Size  Interpretability_Score  \\\n",
      "1        39      Cocktails & Fruit Beverages   184                0.511957   \n",
      "2        15  Italian Cuisine (Pasta & Pizza)    90                0.464549   \n",
      "13       32         Novelty Beverages & Wine    23                0.365000   \n",
      "3        34        Mexican Cuisine (Tex-Mex)    62                0.355992   \n",
      "31        2   Ultra-Rare/Data Quality Issues    13                0.315000   \n",
      "4        30   Asian Cuisine (Chinese & Thai)    53                0.307454   \n",
      "35       37      Miscellaneous Dessert Items    11                0.305000   \n",
      "8        29    Indian Cuisine (Spices & Dal)    32                0.246395   \n",
      "21       24            Candy & Cereal Treats    16                0.222857   \n",
      "6        40      Creamy Cocktails & Liqueurs    38                0.219570   \n",
      "5        12      Seafood Salads & Sandwiches    38                0.209800   \n",
      "7        13         BBQ & Ribs (Pork Dishes)    33                0.195849   \n",
      "17       38         Chocolate Baking (Cocoa)    20                0.195637   \n",
      "10       22      Bread Making (Yeast Baking)    27                0.192444   \n",
      "12       25    Healthy Baking (Whole Grains)    24                0.191488   \n",
      "\n",
      "                                    Distinctive_Terms  \n",
      "1               liqueur, juice, yogurt, vodka, orange  \n",
      "2                pasta, pizza, sauce, italian, tomato  \n",
      "13                       wine, soda, cherry, ice, tea  \n",
      "3                  tortilla, corn, beans, chile, taco  \n",
      "31  turkey, torito adobo, turkey slices, lightlife...  \n",
      "4              paste, sauce, noodles, chinese, sesame  \n",
      "35  cups, cream, shortcake, yogurtcovered pretzels...  \n",
      "8                 dal, powder, seeds, gram, coriander  \n",
      "21  caramel, milk chocolate, candy, chocolate, cereal  \n",
      "6         cream, chocolate, liqueur, vodka, ice cream  \n",
      "5                   tuna, pickle, relish, dill, salad  \n",
      "7                ribs, pork, mustard, pork ribs, corn  \n",
      "17    chocolate, crumbs, powder, cookie, cocoa powder  \n",
      "10             yeast, bread, dry, bread flour, gluten  \n",
      "12     flour, wheat, bran, bran oat, sugar substitute  \n"
     ]
    }
   ],
   "source": [
    "# Load the cluster results\n",
    "clusters_df = pd.read_csv('cluster_characterization_automated_hdbscan.csv')\n",
    "\n",
    "# Manual interpretation based on results\n",
    "cluster_labels = {\n",
    "    -1: \"Universal Ingredients (Noise)\",\n",
    "    \n",
    "    # Excellent Quality Clusters (Clear semantic meaning)\n",
    "    39: \"Cocktails & Fruit Beverages\",\n",
    "    15: \"Italian Cuisine (Pasta & Pizza)\", \n",
    "    30: \"Asian Cuisine (Chinese & Thai)\",\n",
    "    34: \"Mexican Cuisine (Tex-Mex)\",\n",
    "    22: \"Bread Making (Yeast Baking)\",\n",
    "    25: \"Healthy Baking (Whole Grains)\",\n",
    "    28: \"Box Mixes (Convenience Baking)\",\n",
    "    29: \"Indian Cuisine (Spices & Dal)\",\n",
    "    \n",
    "    # Good Quality Clusters (Meaningful patterns)\n",
    "    12: \"Seafood Salads & Sandwiches\",\n",
    "    13: \"BBQ & Ribs (Pork Dishes)\",\n",
    "    40: \"Creamy Cocktails & Liqueurs\",\n",
    "    38: \"Chocolate Baking (Cocoa)\",\n",
    "    26: \"Dessert Add-ins (Chips & Candy)\",\n",
    "    20: \"Ground Spices (Baking)\",\n",
    "    31: \"Ice Cream & Sweet Syrups\",\n",
    "    \n",
    "    # Fair Quality Clusters (Detectable patterns)\n",
    "    10: \"Baking Mixes (Bisquick)\",\n",
    "    14: \"Fresh Salad Greens\",\n",
    "    5: \"Light Baking (Reduced Fat)\",\n",
    "    16: \"Beef Dishes (Chuck & Roast)\",\n",
    "    6: \"Pie & Pastry Components\",\n",
    "    17: \"Tea & Herbal Ingredients\",\n",
    "    24: \"Candy & Cereal Treats\",\n",
    "    \n",
    "    # Poor Quality Clusters (Weak patterns or data issues)\n",
    "    32: \"Novelty Beverages & Wine\",\n",
    "    37: \"Miscellaneous Dessert Items\",\n",
    "    2: \"Ultra-Rare/Data Quality Issues\",\n",
    "    8: \"Prepared/Convenience Foods\",\n",
    "    27: \"Novelty/Party Foods (Data Issues)\",\n",
    "    21: \"Snacks & Dried Fruits\",\n",
    "    0: \"Low-Fat Alternatives & Soups\",\n",
    "    3: \"Summer Squash & Vegetables\",\n",
    "    18: \"Diet/Reduced Products\",\n",
    "    23: \"Soup Ingredients (Split Peas & Barley)\",\n",
    "    36: \"Fish & Citrus\",\n",
    "    33: \"Flavored Cereals & Schnapps (Data Issues)\",\n",
    "    19: \"Specialty Powders & Creams\",\n",
    "    35: \"Cream Cheese Desserts\",\n",
    "    7: \"Bread & Dressing (Mixed)\",\n",
    "    9: \"Bacon & Savory Items (Data Issues)\",\n",
    "    11: \"Maple & Cinnamon Baking\",\n",
    "    4: \"International Biscuits & Whiskey\",\n",
    "    1: \"Specialty Spreads & Meats\"\n",
    "}\n",
    "\n",
    "clusters_df['Category_Label'] = clusters_df['Cluster'].map(cluster_labels)\n",
    "\n",
    "# Define interpretability score\n",
    "def interpretability_score(row):\n",
    "    if row['Cluster'] == -1:\n",
    "        return 0  # Noise cluster\n",
    "    \n",
    "    # Normalize size\n",
    "    size_score = min(row['Size'] / 100, 1.0)\n",
    "    \n",
    "    # Compute coherence as inverse of frequency spread\n",
    "    if row['Avg_Freq'] > 0:\n",
    "        spread = (row['Max_Freq'] - row['Min_Freq']) / (row['Avg_Freq'] + 1)\n",
    "        coherence_score = 1 / (1 + spread)\n",
    "    else:\n",
    "        coherence_score = 0.5  # fallback for missing data\n",
    "    \n",
    "    return (size_score + coherence_score) / 2\n",
    "\n",
    "# Apply and sort\n",
    "clusters_df['Interpretability_Score'] = clusters_df.apply(interpretability_score, axis=1)\n",
    "clusters_ranked = clusters_df.sort_values('Interpretability_Score', ascending=False)\n",
    "\n",
    "# Show results\n",
    "print(\"\\n=== CLUSTERS RANKED BY INTERPRETABILITY ===\")\n",
    "print(clusters_ranked[['Cluster', 'Category_Label', 'Size', \n",
    "                        'Interpretability_Score', 'Distinctive_Terms']].head(15))\n",
    "\n",
    "# Save to file\n",
    "clusters_ranked.to_csv('clusters_with_labels_hdbscan.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0da11b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLUSTER QUALITY TIER DISTRIBUTION\n",
      "================================================================================\n",
      "              N_Clusters  Total_Ingredients  Avg_Interpretability  \\\n",
      "Quality_Tier                                                        \n",
      "Good                   1                184              0.511957   \n",
      "Fair                   6                252              0.352166   \n",
      "Poor                  34                631              0.143701   \n",
      "\n",
      "              Avg_Ingredient_Freq  \n",
      "Quality_Tier                       \n",
      "Good                   109.000000  \n",
      "Fair                   169.166667  \n",
      "Poor                   520.029412  \n",
      "\n",
      "================================================================================\n",
      "EXAMPLE CLUSTERS BY QUALITY TIER\n",
      "================================================================================\n",
      "\n",
      "GOOD (1 clusters):\n",
      "  • Cluster 39: Cocktails & Fruit Beverages         (n=184, score=0.512)\n",
      "\n",
      "FAIR (6 clusters):\n",
      "  • Cluster 15: Italian Cuisine (Pasta & Pizza)     (n= 90, score=0.465)\n",
      "  • Cluster 34: Mexican Cuisine (Tex-Mex)           (n= 62, score=0.356)\n",
      "  • Cluster 30: Asian Cuisine (Chinese & Thai)      (n= 53, score=0.307)\n",
      "\n",
      "POOR (34 clusters):\n",
      "  • Cluster 12: Seafood Salads & Sandwiches         (n= 38, score=0.210)\n",
      "  • Cluster 40: Creamy Cocktails & Liqueurs         (n= 38, score=0.220)\n",
      "  • Cluster 13: BBQ & Ribs (Pork Dishes)            (n= 33, score=0.196)\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY STATISTICS\n",
      "================================================================================\n",
      "                      Metric Value\n",
      "           Total Ingredients  9864\n",
      "       Clustered Ingredients  1685\n",
      "           Noise Ingredients  8179\n",
      "          Non-noise Clusters    41\n",
      "        Clusters (Excellent)     0\n",
      "             Clusters (Good)     1\n",
      "             Clusters (Fair)     6\n",
      "             Clusters (Poor)    34\n",
      "         Median Cluster Size    16\n",
      "           Mean Cluster Size  26.0\n",
      " Largest Cluster (non-noise)   184\n",
      "Smallest Cluster (non-noise)    10\n",
      "\n",
      "================================================================================\n",
      " ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Generated files:\n",
      "  1. clusters_with_labels_dbscan.csv          - All clusters with semantic labels\n",
      "  2. cluster_quality_detailed.csv      - Deep analysis of showcase clusters\n",
      "  3. clusters_with_quality_tiers.csv   - All clusters with quality classification\n",
      "  4. clustering_summary_statistics.csv - Overall statistics\n",
      "\n",
      "Next steps:\n",
      "  • Create visualizations with this data\n",
      "  • Write report sections using these insights\n",
      "  • Compare with HDBSCAN results\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: Quality Tier Classification\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLUSTER QUALITY TIER DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Classify all non-noise clusters\n",
    "valid_clusters = clusters_df[clusters_df['Cluster'] != -1].copy()\n",
    "\n",
    "def classify_quality_tier(row):\n",
    "    score = row['Interpretability_Score']\n",
    "    if score > 0.7:\n",
    "        return \"Excellent\"\n",
    "    elif score > 0.5:\n",
    "        return \"Good\"\n",
    "    elif score > 0.3:\n",
    "        return \"Fair\"\n",
    "    else:\n",
    "        return \"Poor\"\n",
    "\n",
    "valid_clusters['Quality_Tier'] = valid_clusters.apply(classify_quality_tier, axis=1)\n",
    "\n",
    "# Summary by tier\n",
    "quality_summary = valid_clusters.groupby('Quality_Tier').agg({\n",
    "    'Cluster': 'count',\n",
    "    'Size': 'sum',\n",
    "    'Interpretability_Score': 'mean',\n",
    "    'Avg_Freq': 'mean'\n",
    "}).rename(columns={\n",
    "    'Cluster': 'N_Clusters', \n",
    "    'Size': 'Total_Ingredients',\n",
    "    'Interpretability_Score': 'Avg_Interpretability',\n",
    "    'Avg_Freq': 'Avg_Ingredient_Freq'\n",
    "})\n",
    "\n",
    "# Order by quality\n",
    "tier_order = ['Excellent', 'Good', 'Fair', 'Poor']\n",
    "quality_summary = quality_summary.reindex([t for t in tier_order if t in quality_summary.index])\n",
    "\n",
    "print(quality_summary)\n",
    "\n",
    "# Show example clusters for each tier\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLE CLUSTERS BY QUALITY TIER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for tier in tier_order:\n",
    "    tier_clusters = valid_clusters[valid_clusters['Quality_Tier'] == tier]\n",
    "    if len(tier_clusters) > 0:\n",
    "        print(f\"\\n{tier.upper()} ({len(tier_clusters)} clusters):\")\n",
    "        examples = tier_clusters.nlargest(3, 'Size')\n",
    "        for _, row in examples.iterrows():\n",
    "            print(f\"  • Cluster {row['Cluster']:2d}: {row['Category_Label']:<35} \"\n",
    "                  f\"(n={row['Size']:3d}, score={row['Interpretability_Score']:.3f})\")\n",
    "\n",
    "# Save\n",
    "valid_clusters.to_csv('clusters_with_quality_tiers.csv', index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Create Summary Statistics Table\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Ingredients',\n",
    "        'Clustered Ingredients',\n",
    "        'Noise Ingredients',\n",
    "        'Non-noise Clusters',\n",
    "        'Clusters (Excellent)',\n",
    "        'Clusters (Good)',\n",
    "        'Clusters (Fair)',\n",
    "        'Clusters (Poor)',\n",
    "        'Median Cluster Size',\n",
    "        'Mean Cluster Size',\n",
    "        'Largest Cluster (non-noise)',\n",
    "        'Smallest Cluster (non-noise)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        len(ingredient_clusters),\n",
    "        len(ingredient_clusters[ingredient_clusters['cluster'] != -1]),\n",
    "        len(ingredient_clusters[ingredient_clusters['cluster'] == -1]),\n",
    "        len(valid_clusters),\n",
    "        len(valid_clusters[valid_clusters['Quality_Tier'] == 'Excellent']),\n",
    "        len(valid_clusters[valid_clusters['Quality_Tier'] == 'Good']),\n",
    "        len(valid_clusters[valid_clusters['Quality_Tier'] == 'Fair']),\n",
    "        len(valid_clusters[valid_clusters['Quality_Tier'] == 'Poor']),\n",
    "        f\"{valid_clusters['Size'].median():.0f}\",\n",
    "        f\"{valid_clusters['Size'].mean():.1f}\",\n",
    "        valid_clusters['Size'].max(),\n",
    "        valid_clusters['Size'].min()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(summary_stats.to_string(index=False))\n",
    "summary_stats.to_csv('clustering_summary_statistics.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  1. clusters_with_labels_dbscan.csv          - All clusters with semantic labels\")\n",
    "print(\"  2. cluster_quality_detailed.csv      - Deep analysis of showcase clusters\")\n",
    "print(\"  3. clusters_with_quality_tiers.csv   - All clusters with quality classification\")\n",
    "print(\"  4. clustering_summary_statistics.csv - Overall statistics\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  • Create visualizations with this data\")\n",
    "print(\"  • Write report sections using these insights\")\n",
    "print(\"  • Compare with HDBSCAN results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
